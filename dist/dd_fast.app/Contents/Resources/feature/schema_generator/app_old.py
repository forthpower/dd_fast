from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import json
import sqlite3
import re
import ast
import os
import shutil
from datetime import datetime
import requests
import subprocess
import webbrowser
import time
import traceback

app = Flask(__name__, static_folder="static")
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚


# æ•°æ®åº“åˆå§‹åŒ–
def init_db():
    conn = sqlite3.connect("models.db")
    cursor = conn.cursor()
    cursor.execute(
        """
                   CREATE TABLE IF NOT EXISTS models
                   (
                       id
                       INTEGER
                       PRIMARY
                       KEY
                       AUTOINCREMENT,
                       name
                       TEXT
                       NOT
                       NULL
                       UNIQUE,
                       label
                       TEXT
                       NOT
                       NULL,
                       primary_key
                       TEXT,
                       entry
                       TEXT
                       DEFAULT
                       'list',
                       parent
                       TEXT,
                       action
                       TEXT,
                       fields
                       TEXT,
                       base_props
                       TEXT,
                       custom_actions
                       TEXT,
                       created_at
                       TIMESTAMP
                       DEFAULT
                       CURRENT_TIMESTAMP,
                       updated_at
                       TIMESTAMP
                       DEFAULT
                       CURRENT_TIMESTAMP
                   )
                   """
    )

    # åˆ›å»º link_forms è¡¨
    cursor.execute(
        """
                   CREATE TABLE IF NOT EXISTS link_forms
                   (
                       id
                       INTEGER
                       PRIMARY
                       KEY
                       AUTOINCREMENT,
                       name
                       TEXT
                       NOT
                       NULL
                       UNIQUE,
                       fields
                       TEXT
                       NOT
                       NULL,
                       created_at
                       TIMESTAMP
                       DEFAULT
                       CURRENT_TIMESTAMP
                   )
                   """
    )

    # åˆ›å»º inline_models è¡¨
    cursor.execute(
        """
                   CREATE TABLE IF NOT EXISTS inline_models
                   (
                       id
                       INTEGER
                       PRIMARY
                       KEY
                       AUTOINCREMENT,
                       name
                       TEXT
                       NOT
                       NULL
                       UNIQUE,
                       fields
                       TEXT
                       NOT
                       NULL,
                       created_at
                       TIMESTAMP
                       DEFAULT
                       CURRENT_TIMESTAMP
                   )
                   """
    )

    # åˆ›å»º configs è¡¨ï¼ˆç”¨äºæ–‡ä»¶ä¸Šä¼ é…ç½®ï¼‰
    cursor.execute(
        """
                   CREATE TABLE IF NOT EXISTS configs
                   (
                       id
                       INTEGER
                       PRIMARY
                       KEY
                       AUTOINCREMENT,
                       name
                       TEXT
                       NOT
                       NULL
                       UNIQUE,
                       upload_type
                       TEXT
                       NOT
                       NULL,
                       config
                       TEXT
                       NOT
                       NULL,
                       created_at
                       TIMESTAMP
                       DEFAULT
                       CURRENT_TIMESTAMP
                   )
                   """
    )

    # åˆ›å»º repositories è¡¨ï¼ˆç”¨äºä¿å­˜å¯¼å…¥çš„ä»“åº“è·¯å¾„ï¼‰
    cursor.execute(
        """
                   CREATE TABLE IF NOT EXISTS repositories
                   (
                       id
                       INTEGER
                       PRIMARY
                       KEY
                       AUTOINCREMENT,
                       name
                       TEXT
                       NOT
                       NULL,
                       path
                       TEXT
                       NOT
                       NULL
                       UNIQUE,
                       description
                       TEXT,
                       last_import_at
                       TIMESTAMP
                       DEFAULT
                       CURRENT_TIMESTAMP,
                       created_at
                       TIMESTAMP
                       DEFAULT
                       CURRENT_TIMESTAMP
                   )
                   """
    )

    # åˆ›å»ºé…ç½®è¡¨
    cursor.execute(
        """
                   CREATE TABLE IF NOT EXISTS config
                   (
                       id
                       INTEGER
                       PRIMARY
                       KEY
                       AUTOINCREMENT,
                       key
                       TEXT
                       NOT
                       NULL
                       UNIQUE,
                       value
                       TEXT
                       NOT
                       NULL,
                       description
                       TEXT,
                       updated_at
                       TIMESTAMP
                       DEFAULT
                       CURRENT_TIMESTAMP
                   )
                   """
    )

    # æ’å…¥é»˜è®¤é…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    default_configs = [
        (
            "project_path",
            "/Users/centurygame/PycharmProjects/cg-endpoint-demo",
            "é¡¹ç›®è·¯å¾„",
        ),
        ("project_app", "app.py", "é¡¹ç›®å¯åŠ¨æ–‡ä»¶"),
        ("api_url", "http://10.0.49.158:5004/api/v1/admin/endpoints", "API åœ°å€"),
        (
            "sync_url",
            "http://10.0.49.158:5004/api/v1/admin/endpoints/sync/demo",
            "åŒæ­¥åœ°å€",
        ),
        ("home_url", "http://localhost:8000/home/", "é¦–é¡µåœ°å€"),
        (
            "token",
            "eyJhbGciOiJIUzUxMiIsImlhdCI6MTc2MDAwOTA5OCwiZXhwIjoxNzYxODIzNDk4fQ.eyJ1c2VyX2lkIjoxLCJ1c2VybmFtZSI6InlvbmdqaWFuLmRhaSJ9.jxsAefu1Xmi63wr3o026HMuV5l_MFHdlDBbvik8Pa5WDOYt_ioViKUnaBx231ja6DS5K-Fi11Cjl8dddhYzQ1w",
            "è®¤è¯ Token",
        ),
    ]

    for key, value, description in default_configs:
        cursor.execute(
            "INSERT OR IGNORE INTO config (key, value, description) VALUES (?, ?, ?)",
            (key, value, description),
        )

    conn.commit()
    conn.close()


# åˆå§‹åŒ–æ•°æ®åº“
init_db()


@app.route("/")
def index():
    return app.send_static_file("index.html")  # è¿”å›é™æ€ç›®å½•é‡Œçš„ index.html


# è·å–æ‰€æœ‰æ¨¡å‹
@app.route("/api/models", methods=["GET"])
def get_models():
    conn = sqlite3.connect("models.db")
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM models ORDER BY created_at DESC")
    rows = cursor.fetchall()
    conn.close()

    models = []
    for row in rows:
        model = {
            "id": row[0],
            "name": row[1],
            "label": row[2],
            "primary_key": row[3],
            "entry": row[4],
            "parent": json.loads(row[5]) if row[5] else "",
            "action": json.loads(row[6]) if row[6] else [],
            "fields": json.loads(row[7]) if row[7] else [],
            "base_props": json.loads(row[8]) if row[8] else {},
            "custom_actions": json.loads(row[9]) if row[9] else [],
            "created_at": row[10],
            "updated_at": row[11],
        }
        models.append(model)

    return jsonify(models)


# ä¿å­˜æ¨¡å‹
@app.route("/api/models", methods=["POST"])
def save_model():
    data = request.json

    conn = sqlite3.connect("models.db")
    cursor = conn.cursor()

    # æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦å·²å­˜åœ¨
    cursor.execute("SELECT id FROM models WHERE name = ?", (data.get("name"),))
    existing = cursor.fetchone()

    if existing:
        # æ›´æ–°ç°æœ‰æ¨¡å‹
        cursor.execute(
            """
                       UPDATE models
                       SET label          = ?,
                           primary_key    = ?,
                           entry          = ?,
                           parent         = ?,
                           action         = ?,
                           fields         = ?,
                           base_props     = ?,
                           custom_actions = ?,
                           updated_at     = CURRENT_TIMESTAMP
                       WHERE name = ?
                       """,
            (
                data.get("label"),
                data.get("primary_key", ""),
                data.get("entry", "list"),
                json.dumps(data.get("parent", "")),
                json.dumps(data.get("action", [])),
                json.dumps(data.get("fields", [])),
                json.dumps(data.get("base_props", {})),
                json.dumps(data.get("custom_actions", [])),
                data.get("name"),
            ),
        )
        model_id = existing[0]
    else:
        # åˆ›å»ºæ–°æ¨¡å‹
        cursor.execute(
            """
                       INSERT INTO models (name, label, primary_key, entry, parent, action, fields, base_props,
                                           custom_actions)
                       VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                       """,
            (
                data.get("name"),
                data.get("label"),
                data.get("primary_key", ""),
                data.get("entry", "list"),
                json.dumps(data.get("parent", "")),
                json.dumps(data.get("action", [])),
                json.dumps(data.get("fields", [])),
                json.dumps(data.get("base_props", {})),
                json.dumps(data.get("custom_actions", [])),
            ),
        )
        model_id = cursor.lastrowid

    conn.commit()
    conn.close()

    return jsonify({"success": True, "model_id": model_id})


# åˆ é™¤æ¨¡å‹
@app.route("/api/models/<int:model_id>", methods=["DELETE"])
def delete_model(model_id):
    conn = sqlite3.connect("models.db")
    cursor = conn.cursor()
    cursor.execute("DELETE FROM models WHERE id = ?", (model_id,))
    conn.commit()
    conn.close()

    return jsonify({"success": True})


@app.route("/generate", methods=["POST"])
def generate():
    data = request.json

    # ä¿å­˜åˆ°æ•°æ®åº“
    conn = sqlite3.connect("models.db")
    cursor = conn.cursor()

    # æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦å·²å­˜åœ¨
    cursor.execute("SELECT id FROM models WHERE name = ?", (data.get("name"),))
    existing = cursor.fetchone()

    if existing:
        # æ›´æ–°ç°æœ‰æ¨¡å‹
        cursor.execute(
            """
                       UPDATE models
                       SET label          = ?,
                           primary_key    = ?,
                           entry          = ?,
                           parent         = ?,
                           action         = ?,
                           fields         = ?,
                           base_props     = ?,
                           custom_actions = ?,
                           updated_at     = CURRENT_TIMESTAMP
                       WHERE name = ?
                       """,
            (
                data.get("label"),
                data.get("primary_key", ""),
                data.get("entry", "list"),
                json.dumps(data.get("parent", "")),
                json.dumps(data.get("action", [])),
                json.dumps(data.get("fields", [])),
                json.dumps(data.get("base_props", {})),
                json.dumps(data.get("custom_actions", [])),
                data.get("name"),
            ),
        )
    else:
        # åˆ›å»ºæ–°æ¨¡å‹
        cursor.execute(
            """
                       INSERT INTO models (name, label, primary_key, entry, parent, action, fields, base_props,
                                           custom_actions)
                       VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                       """,
            (
                data.get("name"),
                data.get("label"),
                data.get("primary_key", ""),
                data.get("entry", "list"),
                json.dumps(data.get("parent", "")),
                json.dumps(data.get("action", [])),
                json.dumps(data.get("fields", [])),
                json.dumps(data.get("base_props", {})),
                json.dumps(data.get("custom_actions", [])),
            ),
        )

    conn.commit()
    conn.close()

    return jsonify(data)


# LinkForms API
@app.route("/api/link_forms", methods=["GET"])
def get_link_forms():
    conn = sqlite3.connect("models.db")
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM link_forms")
    rows = cursor.fetchall()
    conn.close()

    link_forms = []
    for row in rows:
        link_forms.append(
            {
                "id": row[0],
                "name": row[1],
                "fields": json.loads(row[2]),
                "created_at": row[3],
            }
        )

    return jsonify(link_forms)


@app.route("/api/link_forms", methods=["POST"])
def save_link_form():
    data = request.json
    conn = sqlite3.connect("models.db")
    cursor = conn.cursor()

    cursor.execute("SELECT id FROM link_forms WHERE name = ?", (data.get("name"),))
    existing = cursor.fetchone()

    if existing:
        cursor.execute(
            """
                       UPDATE link_forms
                       SET fields = ?
                       WHERE name = ?
                       """,
            (json.dumps(data.get("fields", [])), data.get("name")),
        )
    else:
        cursor.execute(
            """
                       INSERT INTO link_forms (name, fields)
                       VALUES (?, ?)
                       """,
            (data.get("name"), json.dumps(data.get("fields", []))),
        )

    conn.commit()
    conn.close()

    return jsonify({"success": True})


# InlineModels API
@app.route("/api/inline_models", methods=["GET"])
def get_inline_models():
    conn = sqlite3.connect("models.db")
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM inline_models")
    rows = cursor.fetchall()
    conn.close()

    inline_models = []
    for row in rows:
        inline_models.append(
            {
                "id": row[0],
                "name": row[1],
                "fields": json.loads(row[2]),
                "created_at": row[3],
            }
        )

    return jsonify(inline_models)


@app.route("/api/inline_models", methods=["POST"])
def save_inline_model():
    data = request.json
    conn = sqlite3.connect("models.db")
    cursor = conn.cursor()

    cursor.execute("SELECT id FROM inline_models WHERE name = ?", (data.get("name"),))
    existing = cursor.fetchone()

    if existing:
        cursor.execute(
            """
                       UPDATE inline_models
                       SET fields = ?
                       WHERE name = ?
                       """,
            (json.dumps(data.get("fields", [])), data.get("name")),
        )
    else:
        cursor.execute(
            """
                       INSERT INTO inline_models (name, fields)
                       VALUES (?, ?)
                       """,
            (data.get("name"), json.dumps(data.get("fields", []))),
        )

    conn.commit()
    conn.close()

    return jsonify({"success": True})


# Configs API
@app.route("/api/configs", methods=["GET"])
def get_configs():
    conn = sqlite3.connect("models.db")
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM configs")
    rows = cursor.fetchall()
    conn.close()

    configs = []
    for row in rows:
        configs.append(
            {
                "id": row[0],
                "name": row[1],
                "upload_type": row[2],
                "config": json.loads(row[3]),
                "created_at": row[4],
            }
        )

    return jsonify(configs)


@app.route("/api/configs", methods=["POST"])
def save_config():
    data = request.json
    conn = sqlite3.connect("models.db")
    cursor = conn.cursor()

    cursor.execute("SELECT id FROM configs WHERE name = ?", (data.get("name"),))
    existing = cursor.fetchone()

    if existing:
        cursor.execute(
            """
                       UPDATE configs
                       SET upload_type = ?,
                           config      = ?
                       WHERE name = ?
                       """,
            (
                data.get("upload_type"),
                json.dumps(data.get("config", {})),
                data.get("name"),
            ),
        )
    else:
        cursor.execute(
            """
                       INSERT INTO configs (name, upload_type, config)
                       VALUES (?, ?, ?)
                       """,
            (
                data.get("name"),
                data.get("upload_type"),
                json.dumps(data.get("config", {})),
            ),
        )

    conn.commit()
    conn.close()

    return jsonify({"success": True})


# Repositories API - ä»“åº“ç®¡ç†
@app.route("/api/repositories", methods=["GET"])
def get_repositories():
    """è·å–æ‰€æœ‰å·²ä¿å­˜çš„ä»“åº“"""
    conn = sqlite3.connect("models.db")
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM repositories ORDER BY last_import_at DESC")
    rows = cursor.fetchall()
    conn.close()

    repositories = []
    for row in rows:
        repositories.append(
            {
                "id": row[0],
                "name": row[1],
                "path": row[2],
                "description": row[3],
                "last_import_at": row[4],
                "created_at": row[5],
            }
        )

    return jsonify(repositories)


@app.route("/api/repositories", methods=["POST"])
def save_repository():
    """ä¿å­˜ä»“åº“ä¿¡æ¯"""
    data = request.json
    conn = sqlite3.connect("models.db")
    cursor = conn.cursor()

    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å·²å­˜åœ¨
    cursor.execute("SELECT id FROM repositories WHERE path = ?", (data.get("path"),))
    existing = cursor.fetchone()

    if existing:
        # æ›´æ–°æœ€åå¯¼å…¥æ—¶é—´
        cursor.execute(
            """
                       UPDATE repositories
                       SET name           = ?,
                           description    = ?,
                           last_import_at = CURRENT_TIMESTAMP
                       WHERE path = ?
                       """,
            (data.get("name"), data.get("description", ""), data.get("path")),
        )
    else:
        # æ–°å¢ä»“åº“
        cursor.execute(
            """
                       INSERT INTO repositories (name, path, description)
                       VALUES (?, ?, ?)
                       """,
            (data.get("name"), data.get("path"), data.get("description", "")),
        )

    conn.commit()
    conn.close()

    return jsonify({"success": True})


@app.route("/api/repositories/<int:repo_id>", methods=["DELETE"])
def delete_repository(repo_id):
    """åˆ é™¤ä»“åº“"""
    conn = sqlite3.connect("models.db")
    cursor = conn.cursor()
    cursor.execute("DELETE FROM repositories WHERE id = ?", (repo_id,))
    conn.commit()
    conn.close()

    return jsonify({"success": True})


# æ¨¡å‹æ–‡ä»¶è§£æåŠŸèƒ½


def parse_model_file(content, file_type="auto"):
    """
    è§£ææ¨¡å‹æ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼š
    - Python SQLAlchemy Modelï¼ˆæ”¯æŒå¤šä¸ªæ¨¡å‹ï¼‰
    - Django Model
    - SQL DDL
    - JSON Schema

    è¿”å›æ ¼å¼ï¼š
    - å•ä¸ªæ¨¡å‹ï¼šè¿”å›å•ä¸ª schema å­—å…¸
    - å¤šä¸ªæ¨¡å‹ï¼šè¿”å›åŒ…å«å¤šä¸ª schema çš„åˆ—è¡¨
    """

    # ç±»å‹æ˜ å°„å­—å…¸
    type_mapping = {
        # Python/SQLAlchemy
        "Integer": "Integer",
        "String": "String",
        "Text": "TextArea",
        "Boolean": "Boolean",
        "DateTime": "DateTime",
        "Float": "Float",
        "Date": "DateTime",
        "Time": "String",
        "JSON": "Json",
        "BigInteger": "Integer",
        "SmallInteger": "Integer",
        "Numeric": "Float",
        "Decimal": "Float",
        # SQL
        "INT": "Integer",
        "INTEGER": "Integer",
        "BIGINT": "Integer",
        "SMALLINT": "Integer",
        "VARCHAR": "String",
        "CHAR": "String",
        "TEXT": "TextArea",
        "BOOLEAN": "Boolean",
        "BOOL": "Boolean",
        "DATETIME": "DateTime",
        "TIMESTAMP": "DateTime",
        "DATE": "DateTime",
        "FLOAT": "Float",
        "DOUBLE": "Float",
        "DECIMAL": "Float",
        "JSON": "Json",
        "BLOB": "File",
    }

    fields = []
    model_name = "imported_model"

    # è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç±»å‹
    if "class" in content and ("db.Model" in content or "models.Model" in content):
        # Python Model (SQLAlchemy or Django)
        file_type = "python"
    elif "CREATE TABLE" in content.upper():
        # SQL DDL
        file_type = "sql"
    elif (
        content.strip().startswith("{")
        or "schema" in content
        and "=" in content
        and "{" in content
    ):
        # JSON æˆ– Python schemaå®šä¹‰
        file_type = "json"

    if file_type == "python":
        # è§£æ Python Model - æ”¯æŒå¤šä¸ªæ¨¡å‹
        schemas = []

        # æ‰¾åˆ°æ‰€æœ‰çš„ç±»å®šä¹‰
        class_pattern = r"class\s+(\w+)\s*\([^)]*(?:db\.Model|models\.Model)[^)]*\):\s*\n((?:(?!^class\s).*\n)*)"
        class_matches = re.finditer(class_pattern, content, re.MULTILINE)

        for class_match in class_matches:
            class_name = class_match.group(1)
            class_body = class_match.group(2)

            # è·³è¿‡ Mixin ç±»å’Œå·¥å…·ç±»
            if "Mixin" in class_name or class_name in ["Tool"]:
                continue

            model_name = class_name.lower()
            model_fields = []

            # æå– __tablename__
            tablename_match = re.search(
                r'__tablename__\s*=\s*[\'"](\w+)[\'"]', class_body
            )
            if tablename_match:
                model_name = tablename_match.group(1)

            # æå–å­—æ®µå®šä¹‰
            field_patterns = [
                r"(\w+)\s*=\s*db\.Column\s*\((.*?)\)",
                r"(\w+)\s*=\s*models\.\w+Field\s*\((.*?)\)",
                r"(\w+)\s*=\s*Column\s*\((.*?)\)",
            ]

            for pattern in field_patterns:
                matches = re.finditer(pattern, class_body, re.MULTILINE)
                for match in matches:
                    field_name = match.group(1)
                    field_def = match.group(2)

                    # è·³è¿‡ç§æœ‰å­—æ®µå’Œç‰¹æ®Šå­—æ®µ
                    if field_name.startswith("_") or field_name in [
                        "metadata",
                        "query",
                    ]:
                        continue

                    # æ¨æ–­ç±»å‹
                    field_type = "String"  # é»˜è®¤ç±»å‹
                    for py_type, schema_type in type_mapping.items():
                        if py_type in field_def:
                            field_type = schema_type
                            break

                    # ç‰¹æ®Šå¤„ç† JSON ç±»å‹
                    if "JSON" in field_def or "Json" in field_def:
                        field_type = "Json"

                    # æå–å­—æ®µæ ‡ç­¾
                    label_match = re.search(r'comment=[\'"]([^\'"]+)[\'"]', field_def)
                    label = (
                        label_match.group(1)
                        if label_match
                        else field_name.replace("_", " ").title()
                    )

                    # æ£€æŸ¥æ˜¯å¦å¿…å¡«
                    nullable_match = re.search(
                        r"nullable\s*=\s*(False|True)", field_def
                    )
                    is_required = nullable_match and nullable_match.group(1) == "False"

                    # æ£€æŸ¥æ˜¯å¦ä¸ºä¸»é”®
                    is_primary = (
                        "primary_key=True" in field_def
                        or "primary_key = True" in field_def
                    )

                    # æ£€æŸ¥é»˜è®¤å€¼
                    default_match = re.search(
                        r'default\s*=\s*[\'"]?([^\'",()\s]+)[\'"]?', field_def
                    )
                    default_value = default_match.group(1) if default_match else None

                    # æ„å»ºå­—æ®µé…ç½®
                    field_config = {
                        "name": field_name,
                        "label": label,
                        "type": field_type,
                    }

                    # æ·»åŠ éªŒè¯å™¨
                    if is_required and not is_primary:
                        field_config["validators"] = [{"name": "data_required"}]

                    # ä¸»é”®è®¾ç½®ä¸ºåªè¯»
                    if is_primary:
                        field_config["render_kw"] = {"readonly": True}

                    if default_value and default_value not in [
                        "None",
                        "null",
                        "datetime.now",
                        "datetime.utcnow",
                    ]:
                        field_config["default"] = default_value

                    model_fields.append(field_config)

            # å¦‚æœæœ‰å­—æ®µï¼Œåˆ›å»º schema
            if model_fields:
                # æŸ¥æ‰¾ä¸»é”®å­—æ®µ
                primary_key = "id"
                for field in model_fields:
                    if field.get("render_kw", {}).get("readonly") and field["name"] in [
                        "id",
                        f"{model_name}_id",
                    ]:
                        primary_key = field["name"]
                        break

                schema = {
                    "name": model_name,
                    "label": class_name,
                    "primary_key": primary_key,
                    "entry": "list",
                    "parent": "",
                    "action": [
                        {"name": "list", "template": "tablebase"},
                        {"name": "create", "template": "formbase"},
                        {"name": "edit", "template": "editbase"},
                        {"name": "delete", "template": "button"},
                    ],
                    "fields": model_fields,
                    "base_props": {
                        "column_list": [f["name"] for f in model_fields[:6]],
                        "form_columns": [
                            f["name"]
                            for f in model_fields
                            if not f.get("render_kw", {}).get("readonly")
                        ],
                        "page_size": 20,
                    },
                    "custom_actions": [],
                }
                schemas.append(schema)

        # å¦‚æœæ‰¾åˆ°å¤šä¸ªæ¨¡å‹ï¼Œè¿”å›åˆ—è¡¨ï¼›å¦åˆ™è¿”å›å•ä¸ªæˆ–ç©º
        if len(schemas) > 1:
            return schemas
        elif len(schemas) == 1:
            return schemas[0]
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹ï¼Œç»§ç»­ä½¿ç”¨æ—§é€»è¾‘ï¼ˆå‘åå…¼å®¹ï¼‰

    if file_type == "sql":
        # è§£æ SQL DDL
        # æå–è¡¨å
        table_match = re.search(
            r"CREATE\s+TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?`?(\w+)`?",
            content,
            re.IGNORECASE,
        )
        if table_match:
            model_name = table_match.group(1).lower()

        # æå–å­—æ®µå®šä¹‰
        # åŒ¹é…å­—æ®µè¡Œ
        field_pattern = r"`?(\w+)`?\s+([\w()]+)(?:\s+([^,\n]+))?"
        matches = re.finditer(field_pattern, content)

        for match in matches:
            field_name = match.group(1)
            sql_type = match.group(2).upper()
            constraints = match.group(3) or ""

            # è·³è¿‡ PRIMARY KEY, FOREIGN KEY ç­‰çº¦æŸ
            if field_name.upper() in [
                "PRIMARY",
                "FOREIGN",
                "KEY",
                "INDEX",
                "CONSTRAINT",
                "UNIQUE",
            ]:
                continue

            # æ¨æ–­ç±»å‹
            field_type = "String"
            for sql_t, schema_type in type_mapping.items():
                if sql_type.startswith(sql_t):
                    field_type = schema_type
                    break

            # æ£€æŸ¥æ˜¯å¦å¿…å¡«
            is_required = "NOT NULL" in constraints.upper()

            # æ£€æŸ¥é»˜è®¤å€¼
            default_match = re.search(
                r'DEFAULT\s+[\'"]?([^\'",()\s]+)[\'"]?', constraints, re.IGNORECASE
            )
            default_value = default_match.group(1) if default_match else None

            # æ£€æŸ¥æ³¨é‡Š
            comment_match = re.search(
                r'COMMENT\s+[\'"]([^\'"]+)[\'"]', constraints, re.IGNORECASE
            )
            label = comment_match.group(1) if comment_match else field_name

            # æ„å»ºå­—æ®µé…ç½®
            field_config = {"name": field_name, "label": label, "type": field_type}

            if is_required:
                field_config["validators"] = [{"name": "data_required"}]

            if default_value and default_value.upper() not in [
                "NULL",
                "CURRENT_TIMESTAMP",
            ]:
                field_config["default"] = default_value

            fields.append(field_config)

    elif file_type == "json":
        # è§£æ JSON Schema æˆ–ç°æœ‰é…ç½®ï¼ˆæ”¯æŒPythonæ ¼å¼çš„schemaå®šä¹‰ï¼‰
        data = None

        # é¦–å…ˆå°è¯•ç”¨ JSON è§£æ
        try:
            data = json.loads(content)
        except json.JSONDecodeError:
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä½œä¸ºPythonä»£ç è§£æ
            try:
                # ç›´æ¥æå– schema = {...} çš„å†…å®¹ï¼Œè·³è¿‡å‰é¢çš„ import è¯­å¥
                schema_match = re.search(r"schema\s*=\s*(\{.*\})", content, re.DOTALL)
                if schema_match:
                    schema_str = schema_match.group(1)
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ° schema = {...}ï¼Œå°è¯•ç›´æ¥è§£ææ•´ä¸ªå†…å®¹
                    schema_str = content

                # ç§»é™¤Pythonæ³¨é‡Šï¼ˆè¡Œå°¾çš„ # æ³¨é‡Šï¼‰
                lines = schema_str.split("\n")
                cleaned_lines = []
                for line in lines:
                    # æ£€æŸ¥æ˜¯å¦åœ¨å­—ç¬¦ä¸²å†…
                    in_string = False
                    quote_char = None
                    cleaned_line = []
                    i = 0
                    while i < len(line):
                        char = line[i]
                        # å¤„ç†å­—ç¬¦ä¸²
                        if char in ['"', "'"]:
                            if not in_string:
                                in_string = True
                                quote_char = char
                            elif char == quote_char and (i == 0 or line[i - 1] != "\\"):
                                in_string = False
                                quote_char = None
                            cleaned_line.append(char)
                        # å¤„ç†æ³¨é‡Š
                        elif char == "#" and not in_string:
                            # é‡åˆ°æ³¨é‡Šï¼Œè·³è¿‡å‰©ä½™éƒ¨åˆ†
                            break
                        else:
                            cleaned_line.append(char)
                        i += 1
                    cleaned_lines.append("".join(cleaned_line))

                schema_str = "\n".join(cleaned_lines)

                # å¤„ç† copy_rule çš„ç‰¹æ®Šæ ¼å¼
                # 1. {"å¼€å¯"} -> ç§»é™¤æ•´è¡Œï¼ˆä½¿ç”¨é»˜è®¤è¡Œä¸ºï¼‰
                schema_str = re.sub(
                    r'"copy_rule":\s*\{\s*["\']å¼€å¯["\']\s*\}\s*,?\s*\n?',
                    "",
                    schema_str,
                )
                # 2. {} ä¿æŒåŸæ ·ï¼ˆå¯å¤åˆ¶æœ‰æŒ‰é’®ï¼‰
                # 3. "å…³é—­" ä¿æŒåŸæ ·ï¼ˆä¸å¯å¤åˆ¶ï¼‰

                # æ¸…ç†ä¸å¯æ‰“å°å­—ç¬¦
                schema_str = "".join(
                    char for char in schema_str if char.isprintable() or char in "\n\t"
                )

                # æŸ¥æ‰¾å¹¶è®°å½•å¸¸é‡å¼•ç”¨
                constants_found = []

                # æŸ¥æ‰¾æ‰€æœ‰å¸¸é‡å¼•ç”¨æ¨¡å¼
                constant_patterns = [
                    r":\s*([A-Za-z_][A-Za-z0-9_]*\.[A-Z_][A-Z0-9_]*)\s*([,\}\]])",  # ClassName.ATTRIBUTE
                    r":\s*([A-Z_][A-Z0-9_]*)\s*([,\}\]])",  # CONSTANT_NAME
                ]

                def replace_and_record(match):
                    constant_ref = match.group(1)
                    if constant_ref not in constants_found:
                        constants_found.append(constant_ref)
                    return ": []" + match.group(2)

                # æ›¿æ¢å¸¸é‡å¼•ç”¨ä¸ºç©ºåˆ—è¡¨å¹¶è®°å½•
                for pattern in constant_patterns:
                    schema_str = re.sub(pattern, replace_and_record, schema_str)

                # ä½¿ç”¨ ast.literal_eval è§£æ
                data = ast.literal_eval(schema_str)

                # æ ‡è®°å¸¸é‡å¼•ç”¨
                if constants_found:
                    print(f"     ğŸ” å‘ç°å¸¸é‡å¼•ç”¨: {', '.join(constants_found)}")
                    data["_has_constants"] = True
                    data["_constants_used"] = constants_found

                    # åœ¨å­—æ®µä¸­æ ‡è®°å¸¸é‡å¼•ç”¨
                    if "fields" in data and isinstance(data["fields"], list):
                        for field in data["fields"]:
                            if isinstance(field, dict):
                                field["_has_constants"] = True
                                field["_constant_refs"] = constants_found
            except (ValueError, SyntaxError) as e:
                print(f"Python parsing error: {e}")
                print(f"Content: {schema_str[:500]}")  # æ‰“å°å‰500ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•
                pass

        # å¦‚æœæˆåŠŸè§£æäº†æ•°æ®
        if data and isinstance(data, dict):
            # å¦‚æœæ˜¯å®Œæ•´çš„ schema
            if "name" in data and "fields" in data:
                return data
            # å¦‚æœæ˜¯å­—æ®µå®šä¹‰
            elif "properties" in data:
                # JSON Schema format
                model_name = data.get("title", "imported_model").lower()
                for field_name, field_def in data["properties"].items():
                    json_type = field_def.get("type", "string")
                    field_type = {
                        "string": "String",
                        "integer": "Integer",
                        "number": "Float",
                        "boolean": "Boolean",
                        "object": "Json",
                        "array": "Json",
                    }.get(json_type, "String")

                    fields.append(
                        {
                            "name": field_name,
                            "label": field_def.get("title", field_name),
                            "type": field_type,
                        }
                    )

    # å‘åå…¼å®¹ï¼šå¦‚æœæ²¡æœ‰è§£æåˆ°å­—æ®µï¼Œå°è¯•ç®€å•çš„é”®å€¼å¯¹
    if not fields and file_type not in ["python"]:  # Python å·²ç»å¤„ç†äº†å¤šæ¨¡å‹
        # å°è¯•è§£æç®€å•çš„å­—æ®µåˆ—è¡¨ï¼ˆä¸€è¡Œä¸€ä¸ªå­—æ®µåï¼‰
        lines = content.strip().split("\n")
        for line in lines:
            line = line.strip()
            if line and not line.startswith("#") and not line.startswith("//"):
                # ç®€å•çš„å­—æ®µå
                field_name = re.sub(r"[^\w]", "", line)
                if field_name:
                    fields.append(
                        {
                            "name": field_name,
                            "label": field_name.replace("_", " ").title(),
                            "type": "String",
                        }
                    )

    # æ„å»ºå®Œæ•´çš„ schemaï¼ˆå‘åå…¼å®¹å•æ¨¡å‹åœºæ™¯ï¼‰
    if fields:
        schema = {
            "name": model_name,
            "label": model_name.replace("_", " ").title(),
            "primary_key": "id",
            "entry": "list",
            "parent": "",
            "action": [
                {"name": "list", "template": "tablebase"},
                {"name": "create", "template": "formbase"},
                {"name": "edit", "template": "editbase"},
                {"name": "delete", "template": "button"},
            ],
            "fields": fields,
            "base_props": {
                "column_list": [f["name"] for f in fields[:6]],  # é»˜è®¤æ˜¾ç¤ºå‰6ä¸ªå­—æ®µ
                "form_columns": [f["name"] for f in fields if f["name"] != "id"],
                "page_size": 20,
            },
            "custom_actions": [],
        }
        return schema

    # å¦‚æœä»€ä¹ˆéƒ½æ²¡è§£æåˆ°ï¼Œè¿”å›ç©º schema
    return {
        "name": "imported_model",
        "label": "Imported Model",
        "primary_key": "id",
        "entry": "list",
        "parent": "",
        "action": [
            {"name": "list", "template": "tablebase"},
            {"name": "create", "template": "formbase"},
            {"name": "edit", "template": "editbase"},
            {"name": "delete", "template": "button"},
        ],
        "fields": [],
        "base_props": {"column_list": [], "form_columns": [], "page_size": 20},
        "custom_actions": [],
    }


@app.route("/api/parse_model", methods=["POST"])
def parse_model():
    """è§£ææ¨¡å‹æ–‡ä»¶å¹¶è¿”å› schema é…ç½®ï¼ˆæ”¯æŒå•ä¸ªæˆ–å¤šä¸ªæ¨¡å‹ï¼‰"""
    try:
        data = request.json
        content = data.get("content", "")
        file_type = data.get("file_type", "auto")

        result = parse_model_file(content, file_type)

        # åˆ¤æ–­æ˜¯å•ä¸ªæ¨¡å‹è¿˜æ˜¯å¤šä¸ªæ¨¡å‹
        is_multiple = isinstance(result, list)

        return jsonify(
            {
                "success": True,
                "schema": result if not is_multiple else None,  # å•ä¸ªæ¨¡å‹
                "schemas": result if is_multiple else None,  # å¤šä¸ªæ¨¡å‹
                "is_multiple": is_multiple,
                "count": len(result) if is_multiple else 1,
            }
        )
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 400


@app.route("/api/import_folder", methods=["POST"])
def import_folder():
    """
    æ‰¹é‡å¯¼å…¥æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ schema æ–‡ä»¶

    è¯·æ±‚æ ¼å¼ï¼š
    {
        "folder_path": "/path/to/schemas"
    }

    è¿”å›æ ¼å¼ï¼š
    {
        "success": True,
        "schemas": [...],  # æ‰€æœ‰è§£æçš„schemaåˆ—è¡¨
        "parent_menus": [...],  # è‡ªåŠ¨è¯†åˆ«çš„çˆ¶èœå•åˆ—è¡¨
        "message": "æˆåŠŸå¯¼å…¥ X ä¸ªæ–‡ä»¶"
    }
    """
    try:
        data = request.get_json()
        folder_path = data.get("folder_path", "").strip()

        if not folder_path:
            return jsonify({"success": False, "error": "è¯·æä¾›æ–‡ä»¶å¤¹è·¯å¾„"}), 400

        # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
        if not os.path.exists(folder_path):
            return (
                jsonify({"success": False, "error": f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}"}),
                400,
            )

        if not os.path.isdir(folder_path):
            return (
                jsonify({"success": False, "error": f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶å¤¹: {folder_path}"}),
                400,
            )

        # ä»ç»å¯¹è·¯å¾„ä¸­æå– cg- å¼€å¤´çš„æ–‡ä»¶å¤¹åä½œä¸ºä»“åº“å
        repo_name = None
        path_parts = folder_path.split(os.sep)
        for part in path_parts:
            if part.startswith("cg-"):
                repo_name = part
                break

        print(f"\n{'='*60}")
        print(f"ğŸ“¦ å¼€å§‹æ‰«ææ–‡ä»¶å¤¹")
        print(f"   è·¯å¾„: {folder_path}")
        print(f"   ä»“åº“å: {repo_name or 'æœªæ£€æµ‹åˆ°'}")
        print(f"{'='*60}\n")

        # é€’å½’æ‰«ææ‰€æœ‰æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
        py_files = []
        skipped_files = []
        processed_dirs = []

        for root, dirs, files in os.walk(folder_path):
            # è®°å½•è¿›å…¥çš„æ–‡ä»¶å¤¹
            rel_path = os.path.relpath(root, folder_path)
            if rel_path != ".":
                processed_dirs.append(rel_path)
                print(f"ğŸ“‚ è¿›å…¥æ–‡ä»¶å¤¹: {rel_path}")

            # å¤„ç†å½“å‰æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶
            for filename in files:
                file_path = os.path.join(root, filename)
                rel_file_path = os.path.relpath(file_path, folder_path)

                # å¦‚æœæ˜¯ .py æ–‡ä»¶ä¸”ä¸ä»¥ __ å¼€å¤´ï¼Œåˆ™æ·»åŠ åˆ°å¤„ç†åˆ—è¡¨
                if filename.endswith(".py"):
                    if not filename.startswith("__"):
                        py_files.append(file_path)
                        print(f"  âœ… æ‰¾åˆ° Python æ–‡ä»¶: {rel_file_path}")
                    else:
                        skipped_files.append(rel_file_path)
                        print(f"  â­ï¸  è·³è¿‡ (__ å¼€å¤´): {rel_file_path}")
                else:
                    # å…¶ä»–ç±»å‹çš„æ–‡ä»¶ï¼Œè·³è¿‡
                    skipped_files.append(rel_file_path)
                    print(f"  â­ï¸  è·³è¿‡ (é .py): {rel_file_path}")

        print(f"\n{'='*60}")
        print(f"ğŸ“Š æ‰«æå®Œæˆç»Ÿè®¡")
        print(f"   å¤„ç†æ–‡ä»¶å¤¹æ•°: {len(processed_dirs) + 1}")  # +1 æ˜¯æ ¹ç›®å½•
        print(f"   æ‰¾åˆ° .py æ–‡ä»¶: {len(py_files)}")
        print(f"   è·³è¿‡çš„æ–‡ä»¶: {len(skipped_files)}")
        print(f"{'='*60}\n")

        if not py_files:
            return (
                jsonify(
                    {
                        "success": False,
                        "error": f"æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„ .py æ–‡ä»¶ï¼ˆå·²é€’å½’æœç´¢æ‰€æœ‰å­æ–‡ä»¶å¤¹ï¼‰\næ‰«æäº† {len(processed_dirs) + 1} ä¸ªæ–‡ä»¶å¤¹ï¼Œè·³è¿‡äº† {len(skipped_files)} ä¸ªæ–‡ä»¶",
                    }
                ),
                400,
            )

        # è§£ææ‰€æœ‰æ–‡ä»¶
        print(f"ğŸ” å¼€å§‹è§£æ {len(py_files)} ä¸ª Python æ–‡ä»¶\n")

        schemas = []
        parent_menus_dict = {}  # ä½¿ç”¨å­—å…¸å»é‡
        failed_files = []

        for idx, file_path in enumerate(py_files, 1):
            rel_file_path = os.path.relpath(file_path, folder_path)
            print(f"[{idx}/{len(py_files)}] è§£æ: {rel_file_path}")

            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()

                # ç›´æ¥è§£ææ–‡ä»¶å†…å®¹ï¼Œè·³è¿‡æ³¨é‡Š
                parsed = parse_model_file(content, "json")

                if parsed and "name" in parsed:
                    # æ·»åŠ æºæ–‡ä»¶è·¯å¾„ä¿¡æ¯ï¼Œç”¨äºè‡ªåŠ¨åŒæ­¥
                    parsed["source_file"] = file_path
                    # æ·»åŠ ä»“åº“åä¿¡æ¯
                    if repo_name:
                        parsed["repo_name"] = repo_name
                    if (
                        parsed["label"] == "imported_model"
                        or parsed["name"] == "imported_model"
                    ):
                        parsed["label"] = parsed["name"]
                    schemas.append(parsed)
                    print(
                        f"     âœ… æˆåŠŸè§£æ: {parsed.get('label', parsed.get('name', 'æœªå‘½å'))}"
                    )

                # æå–çˆ¶èœå•ä¿¡æ¯ï¼ˆå¯¹ä¸¤ç§ç±»å‹çš„è§£æç»“æœéƒ½é€‚ç”¨ï¼‰
                if (
                    "parsed" in locals()
                    and parsed
                    and "parent" in parsed
                    and parsed["parent"]
                ):
                    parent_info = parsed["parent"]

                    # å¦‚æœ parent æ˜¯å­—ç¬¦ä¸²ï¼Œè¯´æ˜åªæœ‰ labelï¼ˆå†…éƒ¨æ ‡è¯†ç¬¦ï¼‰
                    if isinstance(parent_info, str):
                        if parent_info and parent_info not in parent_menus_dict:
                            parent_menus_dict[parent_info] = {
                                "label": parent_info,  # label æ˜¯å†…éƒ¨æ ‡è¯†ç¬¦
                                "name": parent_info.title(),  # name æ˜¯é¡µé¢å±•ç¤ºçš„å­—ç¬¦ä¸²
                            }
                    # å¦‚æœ parent æ˜¯å­—å…¸ï¼ŒåŒ…å« label å’Œ name
                    elif isinstance(parent_info, dict) and "label" in parent_info:
                        parent_label = parent_info["label"]
                        if parent_label and parent_label not in parent_menus_dict:
                            parent_menus_dict[parent_label] = {
                                "label": parent_label,  # label æ˜¯å†…éƒ¨æ ‡è¯†ç¬¦
                                "name": parent_info.get(
                                    "name", parent_label.title()
                                ),  # name æ˜¯é¡µé¢å±•ç¤ºçš„å­—ç¬¦ä¸²
                            }

            except Exception as e:
                print(f"     âŒ è§£æé”™è¯¯: {str(e)}")
                failed_files.append(os.path.basename(file_path))

        # è½¬æ¢çˆ¶èœå•å­—å…¸ä¸ºåˆ—è¡¨
        parent_menus = list(parent_menus_dict.values())

        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        print(f"\n{'='*60}")
        print(f"âœ¨ å¯¼å…¥å®Œæˆ")
        print(f"   æˆåŠŸè§£æ: {len(schemas)} ä¸ªæ¨¡å‹")
        print(f"   çˆ¶èœå•: {len(parent_menus)} ä¸ª")
        print(f"   è§£æå¤±è´¥: {len(failed_files)} ä¸ª")
        print(f"{'='*60}\n")

        # æ„å»ºè¿”å›æ¶ˆæ¯
        message = f"æˆåŠŸå¯¼å…¥ {len(schemas)} ä¸ªæ¨¡å‹"
        if repo_name:
            message = f"ğŸ“¦ {repo_name}: " + message
        if parent_menus:
            message += f"ï¼Œè‡ªåŠ¨è¯†åˆ« {len(parent_menus)} ä¸ªçˆ¶èœå•"
        if failed_files:
            message += f"\n\nè§£æå¤±è´¥çš„æ–‡ä»¶ ({len(failed_files)}): {', '.join(failed_files[:5])}"  # åªæ˜¾ç¤ºå‰5ä¸ª
            if len(failed_files) > 5:
                message += f"... (è¿˜æœ‰ {len(failed_files) - 5} ä¸ª)"

        return jsonify(
            {
                "success": True,
                "schemas": schemas,
                "parent_menus": parent_menus,
                "repo_name": repo_name,  # æ·»åŠ ä»“åº“å
                "message": message,
                "total_files": len(py_files),
                "success_count": len(schemas),
                "failed_count": len(failed_files),
                "failed_files": failed_files,
            }
        )

    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route("/api/auto_sync", methods=["POST"])
def auto_sync():
    """
    è‡ªåŠ¨åŒæ­¥åŠŸèƒ½ - å°†ç”Ÿæˆçš„ schema å†™å›åˆ°æºæ–‡ä»¶

    æ¥æ”¶å‰ç«¯ä¼ æ¥çš„ sync_dataï¼ŒåŒ…å«ï¼š
    - file_path: æºæ–‡ä»¶è·¯å¾„
    - schema_content: ç”Ÿæˆçš„ schema å†…å®¹
    - model_name: æ¨¡å‹åç§°

    è¿”å›æ ¼å¼ï¼š
    {
        "success": True,
        "success_count": 3,
        "failed_count": 0,
        "details": ["model1 åŒæ­¥æˆåŠŸ", "model2 åŒæ­¥æˆåŠŸ", ...]
    }
    """
    try:
        data = request.get_json()
        sync_data = data.get("sync_data", [])

        if not sync_data:
            return jsonify({"success": False, "error": "æ²¡æœ‰æä¾›åŒæ­¥æ•°æ®"}), 400

        # åˆ›å»ºå¤‡ä»½æ–‡ä»¶å¤¹ï¼ˆæŒ‰æ—¶é—´æˆ³ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_root = "backups"
        backup_dir = os.path.join(backup_root, f"sync_{timestamp}")
        os.makedirs(backup_dir, exist_ok=True)

        print(f"\n{'='*60}")
        print(f"ğŸš€ å¼€å§‹è‡ªåŠ¨åŒæ­¥")
        print(f"   æ—¶é—´æˆ³: {timestamp}")
        print(f"   å¤‡ä»½ç›®å½•: {backup_dir}")
        print(f"   åŒæ­¥æ¨¡å‹æ•°: {len(sync_data)}")
        print(f"{'='*60}\n")

        success_count = 0
        failed_count = 0
        details = []

        for item in sync_data:
            file_path = item.get("file_path")
            schema_content = item.get("schema_content")
            model_name = item.get("model_name", "Unknown")

            if not file_path or not schema_content:
                failed_count += 1
                details.append(f"âŒ {model_name}: ç¼ºå°‘æ–‡ä»¶è·¯å¾„æˆ–å†…å®¹")
                print(f"âŒ {model_name}: ç¼ºå°‘æ–‡ä»¶è·¯å¾„æˆ–å†…å®¹")
                continue

            try:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if not os.path.exists(file_path):
                    failed_count += 1
                    details.append(f"âŒ {model_name}: æ–‡ä»¶ä¸å­˜åœ¨ ({file_path})")
                    print(f"âŒ {model_name}: æ–‡ä»¶ä¸å­˜åœ¨")
                    continue

                print(f"ğŸ“ åŒæ­¥ {model_name}...")

                # å¤‡ä»½åŸæ–‡ä»¶åˆ°ç‹¬ç«‹æ–‡ä»¶å¤¹
                filename = os.path.basename(file_path)
                backup_file_path = os.path.join(backup_dir, filename)
                shutil.copy2(file_path, backup_file_path)
                print(f"   âœ… å¤‡ä»½å®Œæˆ: {filename}")

                # å†™å…¥æ–°çš„ schema å†…å®¹
                with open(file_path, "w", encoding="utf-8") as f:
                    f.write(schema_content)
                print(f"   âœ… å†™å…¥å®Œæˆ: {file_path}")

                success_count += 1
                details.append(f"âœ… {model_name}: åŒæ­¥æˆåŠŸ")
                print(f"   âœ… åŒæ­¥æˆåŠŸ\n")

            except Exception as e:
                failed_count += 1
                details.append(f"âŒ {model_name}: {str(e)}")
                print(f"   âŒ åŒæ­¥å¤±è´¥: {str(e)}\n")

        # æœ¬åœ°åŒæ­¥æ€»ç»“
        print(f"{'='*60}")
        print(f"ğŸ“Š æœ¬åœ°åŒæ­¥å®Œæˆ")
        print(f"   âœ… æˆåŠŸ: {success_count} ä¸ª")
        print(f"   âŒ å¤±è´¥: {failed_count} ä¸ª")
        print(f"   ğŸ“ å¤‡ä»½: {backup_dir}")
        print(f"{'='*60}\n")

        # é›†æˆè¿œç¨‹åŒæ­¥åŠŸèƒ½ï¼ˆæ¥è‡ª sync.pyï¼‰
        remote_sync_success = False
        remote_sync_message = ""

        # ä»æ•°æ®åº“è·å–é…ç½®
        remote_config = data.get("remote_sync", {})
        enabled = remote_config.get("enabled", True)  # é»˜è®¤å¯ç”¨

        if enabled:
            try:
                # ä»æ•°æ®åº“è¯»å–é…ç½®
                config_conn = sqlite3.connect("models.db")
                config_cursor = config_conn.cursor()
                config_cursor.execute(
                    "SELECT key, value FROM config WHERE key IN (?, ?, ?, ?, ?, ?)",
                    (
                        "project_path",
                        "project_app",
                        "api_url",
                        "sync_url",
                        "home_url",
                        "token",
                    ),
                )
                config_rows = config_cursor.fetchall()
                config_conn.close()

                config_dict = {row[0]: row[1] for row in config_rows}

                # è·å–é…ç½®ï¼ˆä»æ•°æ®åº“ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼‰
                project_path = config_dict.get(
                    "project_path",
                    "/Users/centurygame/PycharmProjects/cg-endpoint-demo",
                )
                project_app = config_dict.get("project_app", "app.py")
                api_url = config_dict.get(
                    "api_url", "http://10.0.49.158:5004/api/v1/admin/endpoints"
                )
                sync_url = config_dict.get(
                    "sync_url",
                    "http://10.0.49.158:5004/api/v1/admin/endpoints/sync/demo",
                )
                home_url = config_dict.get("home_url", "http://localhost:8000/home/")
                token = config_dict.get("token", "")

                headers = {"token": token} if token else {}

                # ç¬¬ä¸€æ­¥ï¼šå¯åŠ¨é¡¹ç›®ï¼ˆå¦‚æœæä¾›äº†é¡¹ç›®è·¯å¾„ï¼‰
                process = None
                if project_path and os.path.exists(project_path):
                    app_file = os.path.join(project_path, project_app)
                    if os.path.exists(app_file):
                        details.append(f"ğŸš€ å‡†å¤‡å¯åŠ¨é¡¹ç›®: {app_file}")

                        # æŸ¥æ‰¾è™šæ‹Ÿç¯å¢ƒ
                        venv_paths = [
                            (
                                ".venv",
                                os.path.join(project_path, ".venv", "bin", "activate"),
                            ),
                            (
                                "venv",
                                os.path.join(project_path, "venv", "bin", "activate"),
                            ),
                            (
                                "env",
                                os.path.join(project_path, "env", "bin", "activate"),
                            ),
                        ]

                        cmd = None
                        venv_used = "system python3"

                        for venv_name, activate_path in venv_paths:
                            if os.path.exists(activate_path):
                                # ä½¿ç”¨ source æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼Œç„¶åæ‰§è¡Œ python3
                                cmd = f"source {activate_path} && python3 {project_app}"
                                venv_used = f"{venv_name}"
                                details.append(f"   æ‰¾åˆ°è™šæ‹Ÿç¯å¢ƒ: {venv_name}")
                                details.append(f"   æ¿€æ´»è„šæœ¬: {activate_path}")
                                break

                        if cmd is None:
                            # æ²¡æœ‰è™šæ‹Ÿç¯å¢ƒï¼Œä½¿ç”¨ç³»ç»Ÿ Python
                            cmd = f"python3 {project_app}"
                            details.append(f"   æœªæ‰¾åˆ°è™šæ‹Ÿç¯å¢ƒï¼Œä½¿ç”¨ç³»ç»Ÿ Python")

                        # åˆ›å»ºæ—¥å¿—æ–‡ä»¶ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
                        log_dir = os.path.join(
                            os.path.dirname(__file__), "backups", "logs"
                        )
                        os.makedirs(log_dir, exist_ok=True)
                        log_file = os.path.join(
                            log_dir, f"project_start_{timestamp}.log"
                        )

                        # åœ¨å‘½ä»¤ä¸­ç›´æ¥é‡å®šå‘è¾“å‡ºï¼Œé¿å…æ–‡ä»¶æè¿°ç¬¦é—®é¢˜ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
                        cmd_with_redirect = f"{cmd} > {log_file} 2>&1 &"

                        details.append(f"   æ‰§è¡Œå‘½ä»¤: {cmd}")
                        details.append(f"   å·¥ä½œç›®å½•: {project_path}")
                        details.append(f"   æ—¥å¿—æ–‡ä»¶: {log_file}")

                        try:
                            # ä¸ä½¿ç”¨ nohupï¼Œè€Œæ˜¯ç›´æ¥åå°è¿è¡Œï¼Œé¿å… Flask debug æ¨¡å¼çš„æ–‡ä»¶æè¿°ç¬¦é—®é¢˜
                            # é‡å®šå‘ stdin åˆ° /dev/null è€Œä¸æ˜¯å…³é—­å®ƒ
                            wrapper_cmd = f'bash -c "cd {project_path} && {cmd} > {log_file} 2>&1 </dev/null &"'
                            details.append(f"   å®Œæ•´å¯åŠ¨å‘½ä»¤: {wrapper_cmd}")

                            print(f"\n{'='*60}")
                            print(f"ğŸš€ æ­£åœ¨å¯åŠ¨é¡¹ç›®: {project_path}")
                            print(f"ğŸ“ æ‰§è¡Œå‘½ä»¤: {cmd}")
                            print(f"ğŸ“„ æ—¥å¿—æ–‡ä»¶: {log_file}")
                            print(f"{'='*60}\n")

                            # ä½¿ç”¨ shell ç›´æ¥æ‰§è¡Œï¼Œä¸ä½¿ç”¨ start_new_session
                            # è¿™æ ·å¯ä»¥ä¿ç•™æ–‡ä»¶æè¿°ç¬¦ï¼Œè®© Flask debug æ¨¡å¼æ­£å¸¸å·¥ä½œ
                            subprocess.Popen(
                                wrapper_cmd,
                                shell=True,
                                executable="/bin/bash",
                                stdout=subprocess.PIPE,
                                stderr=subprocess.PIPE,
                                stdin=subprocess.PIPE,
                                close_fds=False,  # ä¸å…³é—­æ–‡ä»¶æè¿°ç¬¦
                            )

                            # ç­‰å¾…è®©è¿›ç¨‹å¯åŠ¨å¹¶å®æ—¶è¯»å–æ—¥å¿—
                            details.append(f"   ç­‰å¾…é¡¹ç›®å¯åŠ¨...")
                            print("â³ ç­‰å¾…é¡¹ç›®å¯åŠ¨...\n")
                            time.sleep(2)

                            # å®æ—¶è¯»å–å¹¶æ‰“å°æ—¥å¿—å‰50è¡Œ
                            if os.path.exists(log_file):
                                try:
                                    with open(log_file, "r") as f:
                                        log_lines = f.readlines()
                                        if log_lines:
                                            print("ğŸ“‹ å¯åŠ¨æ—¥å¿—:")
                                            print("-" * 60)
                                            for i, line in enumerate(log_lines[:50]):
                                                print(line.rstrip())
                                            print("-" * 60)
                                            if len(log_lines) > 50:
                                                print(
                                                    f"... (è¿˜æœ‰ {len(log_lines) - 50} è¡Œï¼ŒæŸ¥çœ‹å®Œæ•´æ—¥å¿—: {log_file})"
                                                )
                                            print()
                                        else:
                                            print(
                                                "âš ï¸  æ—¥å¿—æ–‡ä»¶ä¸ºç©ºï¼Œè¿›ç¨‹å¯èƒ½è¿˜åœ¨å¯åŠ¨ä¸­\n"
                                            )
                                except Exception as e:
                                    print(f"âš ï¸  è¯»å–æ—¥å¿—å¤±è´¥: {str(e)}\n")
                            else:
                                print(f"âš ï¸  æ—¥å¿—æ–‡ä»¶å°šæœªåˆ›å»º: {log_file}\n")

                            time.sleep(1)

                            # æŸ¥æ‰¾å¯åŠ¨çš„è¿›ç¨‹ - æ›´ç²¾ç¡®çš„åŒ¹é…
                            find_process_cmd = f"ps aux | grep 'python3 {project_app}' | grep '{project_path}' | grep -v grep | awk '{{print $2}}'"
                            find_result = subprocess.run(
                                find_process_cmd,
                                shell=True,
                                capture_output=True,
                                text=True,
                            )

                            details.append(f"   æŸ¥æ‰¾è¿›ç¨‹å‘½ä»¤: {find_process_cmd}")
                            details.append(
                                f"   æŸ¥æ‰¾ç»“æœ: '{find_result.stdout.strip()}'"
                            )

                            print(f"ğŸ” æŸ¥æ‰¾è¿›ç¨‹...")
                            print(
                                f"   å‘½ä»¤: ps aux | grep 'python3 {project_app}' | grep '{project_path}'"
                            )

                            if find_result.stdout.strip():
                                # æ‰¾åˆ°äº†è¿›ç¨‹
                                pid_str = find_result.stdout.strip()
                                details.append(f"â±ï¸  é¡¹ç›®å¯åŠ¨ä¸­... (PID: {pid_str})")
                                details.append(f"   ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ: {venv_used}")
                                print(f"âœ… æ‰¾åˆ°è¿›ç¨‹ PID: {pid_str}")
                                print(f"   ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ: {venv_used}\n")
                                process = type(
                                    "obj",
                                    (object,),
                                    {"pid": int(pid_str), "poll": lambda: None},
                                )()
                            else:
                                details.append(f"âŒ æœªæ‰¾åˆ°è¿è¡Œçš„è¿›ç¨‹")
                                details.append(f"   å‘½ä»¤å¯èƒ½æ‰§è¡Œå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—")
                                print(f"âŒ æœªæ‰¾åˆ°è¿è¡Œçš„è¿›ç¨‹")
                                print(f"   å‘½ä»¤å¯èƒ½æ‰§è¡Œå¤±è´¥\n")

                                # å°è¯•é‡æ–°è¯»å–æ—¥å¿—
                                try:
                                    time.sleep(1)
                                    if os.path.exists(log_file):
                                        with open(log_file, "r") as lf:
                                            log_content = lf.read()
                                            if log_content:
                                                details.append(f"   æ—¥å¿—å†…å®¹å‰20è¡Œ:")
                                                print("ğŸ“‹ æœ€æ–°æ—¥å¿—å†…å®¹:")
                                                print("-" * 60)
                                                for line in log_content.split("\n")[
                                                    :20
                                                ]:
                                                    if line.strip():
                                                        details.append(f"     {line}")
                                                        print(line)
                                                print("-" * 60 + "\n")
                                    else:
                                        details.append(f"   æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
                                        print(f"âš ï¸  æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}\n")
                                except Exception as e:
                                    details.append(f"   è¯»å–æ—¥å¿—å¤±è´¥: {str(e)}")
                                    print(f"âš ï¸  è¯»å–æ—¥å¿—å¤±è´¥: {str(e)}\n")

                                process = None

                        except Exception as e:
                            details.append(f"âŒ å¯åŠ¨å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}")
                            details.append(f"   å‘½ä»¤: {cmd_with_redirect}")
                            raise

                        # è½®è¯¢æ£€æŸ¥é¡¹ç›®æ˜¯å¦å¯åŠ¨æˆåŠŸ
                        if process:
                            max_wait = 3
                            waited = 0
                            print(
                                f"ğŸ”„ è½®è¯¢æ£€æŸ¥ API æ˜¯å¦å¯è®¿é—® (æœ€å¤šç­‰å¾… {max_wait} ç§’)...\n"
                            )

                            while waited < max_wait:
                                time.sleep(1)
                                waited += 1

                                # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
                                check_process_cmd = (
                                    f"ps -p {process.pid} > /dev/null 2>&1"
                                )
                                check_result = subprocess.run(
                                    check_process_cmd, shell=True
                                )

                                if check_result.returncode != 0:
                                    # è¿›ç¨‹å·²é€€å‡ºï¼Œè¯´æ˜å¯åŠ¨å¤±è´¥
                                    time.sleep(0.5)  # ç­‰å¾…æ—¥å¿—å†™å…¥å®Œæˆ

                                    details.append(f"âŒ é¡¹ç›®å¯åŠ¨å¤±è´¥ (è¿›ç¨‹å·²é€€å‡º)")
                                    details.append(f"   æ—¥å¿—æ–‡ä»¶: {log_file}")

                                    print(
                                        f"âŒ é¡¹ç›®å¯åŠ¨å¤±è´¥ (è¿›ç¨‹ {process.pid} å·²é€€å‡º)"
                                    )
                                    print(f"   æ—¥å¿—æ–‡ä»¶: {log_file}\n")

                                    # è¯»å–å¹¶æ˜¾ç¤ºé”™è¯¯æ—¥å¿—çš„æœ€åå‡ è¡Œ
                                    try:
                                        with open(log_file, "r") as f:
                                            log_lines = f.readlines()
                                            if log_lines:
                                                details.append(f"   æœ€å 10 è¡Œæ—¥å¿—:")
                                                print("ğŸ“‹ æœ€å 10 è¡Œæ—¥å¿—:")
                                                print("-" * 60)
                                                for line in log_lines[-10:]:
                                                    if line.strip():
                                                        details.append(
                                                            f"     {line.rstrip()}"
                                                        )
                                                        print(line.rstrip())
                                                print("-" * 60 + "\n")
                                    except Exception as e:
                                        details.append(f"   æ— æ³•è¯»å–æ—¥å¿—: {str(e)}")
                                        print(f"âš ï¸  æ— æ³•è¯»å–æ—¥å¿—: {str(e)}\n")
                                    break

                                # å°è¯•è®¿é—® API éªŒè¯å¯åŠ¨
                                try:
                                    test_url = api_url.split("?")[0]
                                    print(
                                        f"   [{waited}/{max_wait}] æ­£åœ¨æ£€æŸ¥ API: {test_url}",
                                        end="",
                                        flush=True,
                                    )
                                    test_response = requests.get(
                                        test_url, headers=headers, timeout=2
                                    )
                                    if test_response.status_code in [200, 401, 403]:
                                        details.append(
                                            f"âœ… é¡¹ç›®å¯åŠ¨æˆåŠŸ (PID: {process.pid}, è€—æ—¶: {waited}ç§’)"
                                        )
                                        details.append(
                                            f"   API å“åº”ç : {test_response.status_code}"
                                        )
                                        print(f" âœ…")
                                        print(f"\nâœ… é¡¹ç›®å¯åŠ¨æˆåŠŸ!")
                                        print(f"   PID: {process.pid}")
                                        print(f"   è€—æ—¶: {waited} ç§’")
                                        print(f"   API: {test_url}")
                                        print(
                                            f"   å“åº”ç : {test_response.status_code}\n"
                                        )
                                        break
                                    else:
                                        print(f" â³ (HTTP {test_response.status_code})")
                                except Exception as e:
                                    # è¿æ¥å¤±è´¥æ˜¯æ­£å¸¸çš„ï¼Œç»§ç»­ç­‰å¾…
                                    print(f" â³ (ç­‰å¾…ä¸­...)")
                                    if waited % 3 == 0:  # æ¯ 3 ç§’è¾“å‡ºä¸€æ¬¡çŠ¶æ€
                                        details.append(
                                            f"   ç­‰å¾…ä¸­... ({waited}/{max_wait}ç§’)"
                                        )
                            else:
                                # è¶…æ—¶
                                check_process_cmd = (
                                    f"ps -p {process.pid} > /dev/null 2>&1"
                                )
                                check_result = subprocess.run(
                                    check_process_cmd, shell=True
                                )

                                if check_result.returncode == 0:
                                    details.append(
                                        f"âš ï¸  é¡¹ç›®å¯åŠ¨è¶…æ—¶ï¼Œä½†è¿›ç¨‹ä»åœ¨è¿è¡Œ (PID: {process.pid})"
                                    )
                                    details.append(
                                        f"   å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´å¯åŠ¨ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥"
                                    )
                                    details.append(f"   æ—¥å¿—æ–‡ä»¶: {log_file}")

                                    print(f"\nâš ï¸  é¡¹ç›®å¯åŠ¨è¶…æ—¶ï¼Œä½†è¿›ç¨‹ä»åœ¨è¿è¡Œ")
                                    print(f"   PID: {process.pid}")
                                    print(f"   å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´å¯åŠ¨ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥")
                                    print(f"   æ—¥å¿—æ–‡ä»¶: {log_file}\n")
                                else:
                                    details.append(f"âŒ é¡¹ç›®å¯åŠ¨è¶…æ—¶ä¸”è¿›ç¨‹å·²é€€å‡º")
                                    details.append(f"   æ—¥å¿—æ–‡ä»¶: {log_file}")

                                    print(f"\nâŒ é¡¹ç›®å¯åŠ¨è¶…æ—¶ä¸”è¿›ç¨‹å·²é€€å‡º")
                                    print(f"   æ—¥å¿—æ–‡ä»¶: {log_file}\n")

                                    # è¯»å–æ—¥å¿—
                                    try:
                                        with open(log_file, "r") as f:
                                            log_lines = f.readlines()
                                            if log_lines:
                                                details.append(f"   æœ€å 10 è¡Œæ—¥å¿—:")
                                                print("ğŸ“‹ æœ€å 10 è¡Œæ—¥å¿—:")
                                                print("-" * 60)
                                                for line in log_lines[-10:]:
                                                    if line.strip():
                                                        details.append(
                                                            f"     {line.rstrip()}"
                                                        )
                                                        print(line.rstrip())
                                                print("-" * 60 + "\n")
                                    except:
                                        pass
                    else:
                        details.append(f"âš ï¸  é¡¹ç›®æ–‡ä»¶ä¸å­˜åœ¨: {app_file}")

                # ç¬¬äºŒæ­¥ï¼šåŒæ­¥ schema
                if sync_url:
                    print(f"{'='*60}")
                    print(f"ğŸ”„ æ­£åœ¨åŒæ­¥ Schema åˆ°è¿œç¨‹...")
                    print(f"   URL: {sync_url}")
                    print(f"{'='*60}\n")

                    time.sleep(1)
                    response = requests.get(sync_url, headers=headers, timeout=10)
                    response.raise_for_status()
                    details.append("âœ… è¿œç¨‹åŒæ­¥: Schema åŒæ­¥æˆåŠŸ")
                    remote_sync_success = True
                    remote_sync_message = "è¿œç¨‹åŒæ­¥æˆåŠŸ"

                    print(f"âœ… Schema åŒæ­¥æˆåŠŸ!")
                    print(f"   å“åº”ç : {response.status_code}\n")

                    # åŒæ­¥æˆåŠŸåç­‰å¾…3ç§’ï¼Œç¡®ä¿è¿œç¨‹æœåŠ¡å™¨å¤„ç†å®Œæˆ
                    details.append("â±ï¸  ç­‰å¾…è¿œç¨‹æœåŠ¡å™¨å¤„ç†...")
                    details.append("âœ… è¿œç¨‹å¤„ç†å®Œæˆ")

                # ç¬¬ä¸‰æ­¥ï¼šæ‰“å¼€æµè§ˆå™¨ï¼ˆåªåœ¨è¿œç¨‹åŒæ­¥æˆåŠŸåï¼‰
                if home_url and remote_sync_success:
                    print(f"{'='*60}")
                    print(f"ğŸŒ æ­£åœ¨æ‰“å¼€æµè§ˆå™¨...")
                    print(f"   URL: {home_url}")
                    print(f"{'='*60}\n")

                    webbrowser.open(home_url)
                    details.append(f"ğŸŒ å·²æ‰“å¼€æµè§ˆå™¨: {home_url}")

                    print(f"âœ… æµè§ˆå™¨å·²æ‰“å¼€\n")

            except Exception as e:
                details.append(f"âš ï¸  è¿œç¨‹åŒæ­¥å¤±è´¥: {str(e)}")
                remote_sync_message = f"è¿œç¨‹åŒæ­¥å¤±è´¥: {str(e)}"

                print(f"\nâŒ è¿œç¨‹åŒæ­¥å¤±è´¥!")
                print(f"   é”™è¯¯: {str(e)}")
                print(f"{'='*60}\n")

        # æ„å»ºè¿”å›æ¶ˆæ¯
        message = f"åŒæ­¥å®Œæˆ: æˆåŠŸ {success_count} ä¸ªï¼Œå¤±è´¥ {failed_count} ä¸ª\nå¤‡ä»½ä½ç½®: {backup_dir}"
        if remote_sync_message:
            message += f"\n{remote_sync_message}"

        return jsonify(
            {
                "success": True,
                "success_count": success_count,
                "failed_count": failed_count,
                "details": details,
                "backup_dir": backup_dir,
                "remote_sync": remote_sync_success,
                "message": message,
            }
        )

    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route("/api/test_project_start", methods=["POST"])
def test_project_start():
    """
    æµ‹è¯•é¡¹ç›®å¯åŠ¨ - è°ƒè¯•ç”¨æ¥å£
    """
    try:
        data = request.get_json()
        project_path = data.get(
            "project_path", "/Users/centurygame/PycharmProjects/cg-endpoint-demo"
        )
        project_app = data.get("project_app", "app.py")

        details = []

        # æ£€æŸ¥é¡¹ç›®è·¯å¾„
        if not os.path.exists(project_path):
            return (
                jsonify({"success": False, "error": f"é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: {project_path}"}),
                400,
            )

        app_file = os.path.join(project_path, project_app)
        if not os.path.exists(app_file):
            return (
                jsonify({"success": False, "error": f"é¡¹ç›®æ–‡ä»¶ä¸å­˜åœ¨: {app_file}"}),
                400,
            )

        details.append(f"âœ… é¡¹ç›®è·¯å¾„: {project_path}")
        details.append(f"âœ… é¡¹ç›®æ–‡ä»¶: {app_file}")

        # æŸ¥æ‰¾è™šæ‹Ÿç¯å¢ƒ
        venv_paths = [
            (".venv", os.path.join(project_path, ".venv", "bin", "activate")),
            ("venv", os.path.join(project_path, "venv", "bin", "activate")),
            ("env", os.path.join(project_path, "env", "bin", "activate")),
        ]

        cmd = None
        venv_found = False

        for venv_name, activate_path in venv_paths:
            if os.path.exists(activate_path):
                # ä½¿ç”¨ source æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼Œç„¶åæ‰§è¡Œ python3
                cmd = f"source {activate_path} && python3 {project_app}"
                details.append(f"âœ… æ‰¾åˆ°è™šæ‹Ÿç¯å¢ƒ: {venv_name}")
                details.append(f"   æ¿€æ´»è„šæœ¬: {activate_path}")
                venv_found = True
                break

        if not venv_found:
            cmd = f"python3 {project_app}"
            details.append(f"âš ï¸  æœªæ‰¾åˆ°è™šæ‹Ÿç¯å¢ƒï¼Œå°†ä½¿ç”¨ç³»ç»Ÿ Python")

        # æµ‹è¯• Python ç‰ˆæœ¬
        try:
            # ä½¿ç”¨ç›¸åŒçš„ç¯å¢ƒæµ‹è¯• Python ç‰ˆæœ¬
            if venv_found:
                test_cmd = f"source {activate_path} && python3 --version"
            else:
                test_cmd = "python3 --version"

            version_result = subprocess.run(
                test_cmd,
                capture_output=True,
                text=True,
                shell=True,
                executable="/bin/bash",
                timeout=5,
            )
            python_version = (
                version_result.stdout.strip() or version_result.stderr.strip()
            )
            details.append(f"âœ… Python ç‰ˆæœ¬: {python_version}")
        except Exception as e:
            details.append(f"âš ï¸  æ— æ³•è·å– Python ç‰ˆæœ¬: {str(e)}")

        # åˆ›å»ºæµ‹è¯•æ—¥å¿—ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_dir = os.path.join(os.path.dirname(__file__), "backups", "logs")
        os.makedirs(log_dir, exist_ok=True)
        log_file = os.path.join(log_dir, f"test_start_{timestamp}.log")

        details.append(f"ğŸ“ å¯åŠ¨å‘½ä»¤: {cmd}")
        details.append(f"ğŸ“‚ å·¥ä½œç›®å½•: {project_path}")
        details.append(f"ğŸ“„ æ—¥å¿—æ–‡ä»¶: {log_file}")

        # å¯åŠ¨é¡¹ç›® - é¿å…ä½¿ç”¨ nohupï¼Œé˜²æ­¢ Flask debug æ¨¡å¼çš„æ–‡ä»¶æè¿°ç¬¦é—®é¢˜
        try:
            wrapper_cmd = (
                f'bash -c "cd {project_path} && {cmd} > {log_file} 2>&1 </dev/null &"'
            )
            details.append(f"ğŸ“ å®Œæ•´å¯åŠ¨å‘½ä»¤: {wrapper_cmd}")

            subprocess.Popen(
                wrapper_cmd,
                shell=True,
                executable="/bin/bash",
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                stdin=subprocess.PIPE,
                close_fds=False,
            )

            # ç­‰å¾…ä¸€ä¸‹è®©è¿›ç¨‹å¯åŠ¨
            time.sleep(2)

            # æŸ¥æ‰¾å¯åŠ¨çš„è¿›ç¨‹
            find_process_cmd = f"ps aux | grep '[p]ython3 {project_app}' | grep '{project_path}' | grep -v grep"
            find_result = subprocess.run(
                find_process_cmd, shell=True, capture_output=True, text=True
            )

            if find_result.stdout.strip():
                # æ‰¾åˆ°äº†è¿›ç¨‹
                pid_line = find_result.stdout.strip().split()[1]
                details.append(f"ğŸš€ é¡¹ç›®å·²å¯åŠ¨ (PID: {pid_line})")

                # ç­‰å¾… 5 ç§’æ£€æŸ¥çŠ¶æ€
                time.sleep(5)

                # å†æ¬¡æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨
                check_result = subprocess.run(
                    f"ps -p {pid_line} > /dev/null 2>&1", shell=True
                )

                if check_result.returncode != 0:
                    # è¿›ç¨‹å·²é€€å‡º
                    details.append(f"âŒ é¡¹ç›®å¯åŠ¨å¤±è´¥ (è¿›ç¨‹å·²é€€å‡º)")
                    # è¯»å–æ—¥å¿—
                    try:
                        with open(log_file, "r") as f:
                            log_content = f.read()
                            details.append(f"ğŸ“‹ æ—¥å¿—å†…å®¹:")
                            for line in log_content.split("\n")[-15:]:
                                if line.strip():
                                    details.append(f"   {line}")
                    except Exception as e:
                        details.append(f"   æ— æ³•è¯»å–æ—¥å¿—: {str(e)}")

                    return jsonify(
                        {"success": False, "details": details, "log_file": log_file}
                    )
                else:
                    details.append(f"âœ… é¡¹ç›®è¿›ç¨‹è¿è¡Œä¸­")
                    details.append(f"ğŸ’¡ è¯·æ‰‹åŠ¨æ£€æŸ¥ API æ˜¯å¦å¯è®¿é—®")
                    details.append(f"ğŸ’¡ æ—¥å¿—: {log_file}")

                    return jsonify(
                        {
                            "success": True,
                            "pid": int(pid_line),
                            "details": details,
                            "log_file": log_file,
                        }
                    )
            else:
                details.append(f"âŒ æœªæ‰¾åˆ°è¿è¡Œçš„è¿›ç¨‹")
                details.append(f"   å‘½ä»¤å¯èƒ½æ‰§è¡Œå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—")

                # è¯»å–æ—¥å¿—
                try:
                    time.sleep(1)
                    with open(log_file, "r") as f:
                        log_content = f.read()
                        if log_content:
                            details.append(f"ğŸ“‹ æ—¥å¿—å†…å®¹:")
                            for line in log_content.split("\n")[-15:]:
                                if line.strip():
                                    details.append(f"   {line}")
                except:
                    pass

                return jsonify(
                    {"success": False, "details": details, "log_file": log_file}
                )

        except Exception as e:
            details.append(f"âŒ å¯åŠ¨å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}")
            return jsonify({"success": False, "details": details, "error": str(e)})

    except Exception as e:
        return (
            jsonify(
                {"success": False, "error": str(e), "traceback": traceback.format_exc()}
            ),
            500,
        )


# ==================== é…ç½®ç®¡ç† API ====================


@app.route("/api/config", methods=["GET"])
def get_config():
    """è·å–æ‰€æœ‰é…ç½®"""
    try:
        conn = sqlite3.connect("models.db")
        cursor = conn.cursor()
        cursor.execute("SELECT key, value, description FROM config")
        rows = cursor.fetchall()
        conn.close()

        config = {}
        for key, value, description in rows:
            config[key] = {"value": value, "description": description}

        return jsonify(config)
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/api/config/<key>", methods=["GET"])
def get_config_by_key(key):
    """è·å–å•ä¸ªé…ç½®"""
    try:
        conn = sqlite3.connect("models.db")
        cursor = conn.cursor()
        cursor.execute("SELECT value, description FROM config WHERE key = ?", (key,))
        row = cursor.fetchone()
        conn.close()

        if row:
            return jsonify({"key": key, "value": row[0], "description": row[1]})
        else:
            return jsonify({"error": "é…ç½®ä¸å­˜åœ¨"}), 404
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/api/config", methods=["POST"])
def update_config():
    """æ›´æ–°é…ç½®"""
    try:
        data = request.json
        key = data.get("key")
        value = data.get("value")
        description = data.get("description", "")

        if not key or value is None:
            return jsonify({"error": "ç¼ºå°‘å¿…è¦å‚æ•°"}), 400

        conn = sqlite3.connect("models.db")
        cursor = conn.cursor()

        # ä½¿ç”¨ INSERT OR REPLACE æ›´æ–°é…ç½®
        cursor.execute(
            """
            INSERT OR REPLACE INTO config (key, value, description, updated_at) 
            VALUES (?, ?, ?, CURRENT_TIMESTAMP)
        """,
            (key, value, description),
        )

        conn.commit()
        conn.close()

        return jsonify({"success": True, "message": f"é…ç½® {key} å·²æ›´æ–°"})
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/api/config/batch", methods=["POST"])
def update_config_batch():
    """æ‰¹é‡æ›´æ–°é…ç½®"""
    try:
        configs = request.json

        if not isinstance(configs, dict):
            return jsonify({"error": "å‚æ•°æ ¼å¼é”™è¯¯"}), 400

        conn = sqlite3.connect("models.db")
        cursor = conn.cursor()

        for key, value in configs.items():
            cursor.execute(
                """
                INSERT OR REPLACE INTO config (key, value, updated_at) 
                VALUES (?, ?, CURRENT_TIMESTAMP)
            """,
                (key, value),
            )

        conn.commit()
        conn.close()

        return jsonify({"success": True, "message": f"å·²æ›´æ–° {len(configs)} ä¸ªé…ç½®"})
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# æ˜¾å¼æä¾›é™æ€æ–‡ä»¶ï¼ˆCSSã€JS ç­‰ï¼‰
@app.route("/<path:filename>")
def static_files(filename):
    return send_from_directory(app.static_folder, filename)


if __name__ == "__main__":
    print(app.url_map)
    # ç¦ç”¨ reloader é¿å…è¿›ç¨‹ä¸é€€å‡ºçš„é—®é¢˜
    # å¦‚æœéœ€è¦è‡ªåŠ¨é‡è½½åŠŸèƒ½ï¼Œå¯ä»¥æ”¹ä¸º use_reloader=Trueï¼Œä½†éœ€è¦æ‰‹åŠ¨æ€è¿›ç¨‹
    app.run(host="0.0.0.0", port=5010, debug=True, use_reloader=False)
